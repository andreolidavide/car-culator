{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import sys\n",
    "import unicodedata\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "automobile_url = \"https://www.automobile.it/usate/page-1\"\n",
    "response = requests.get(automobile_url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "# Initialize the empty car list, which will hold all the cars scraped from the website\n",
    "car_list = []\n",
    "\n",
    "# The website is structured like this: there is a list of all the cars that are on the market, divided in pages. Each page contains a few cars ads.\n",
    "# By clicking on an ad, you are then brought to a page with the details related to the car in that ad, like cahracteristics and price.\n",
    "\n",
    "# Find the maximum number of pages\n",
    "max_pages = int(soup.find_all('button', class_=\"jsx-2138479547 font-base auto inline-circled styled value\")[-1].text)\n",
    "# Iterate over the range 1 to max number of pages\n",
    "for i in range(1, max_pages +1):\n",
    "    # Construct the url of the page, get the html and parse it\n",
    "    page_url = \"https://www.automobile.it/usate/page-\" + str(i)\n",
    "    page_response = requests.get(page_url)\n",
    "    print(page_url)\n",
    "    page_soup = BeautifulSoup(page_response.text, 'html.parser')\n",
    "    # Extract all the cars ad on the current page and iterate over them\n",
    "    car_ads_list = page_soup.find_all('a', class_=\"jsx-2059509079 Card hover-effect CardAd\")\n",
    "    for car_ad in car_ads_list:\n",
    "        # Create empty car object\n",
    "        car = {}\n",
    "        # Extract the url of the details of the ad, get the html and parse it\n",
    "        car_details_page_url = \"https://www.automobile.it\" + car_ad.attrs['href']\n",
    "        print(car_details_page_url)\n",
    "        car_details_response = requests.get(car_details_page_url)\n",
    "        car_details_page = BeautifulSoup(car_details_response.text, 'html.parser')\n",
    "        # Sometimes the links are broken and lead to a 404 page, if that is the case this iteration will be skipped\n",
    "        if car_details_page.find('div', class_='jsx-1421767171 PageNotFound'):\n",
    "            continue\n",
    "        # Get the price and assign it to the car object\n",
    "        car_price = car_details_page.find('span',class_=\"jsx-139447011 Price\").text\n",
    "        car['price'] = car_price\n",
    "        # Get the car characteristics groups and iterate over them\n",
    "        car_characteristics_groups = car_details_page.find_all('div', class_=\"jsx-3587327592 Item\")\n",
    "        for characteristic_group in car_characteristics_groups:\n",
    "            # Get the category name for the characteristics group\n",
    "            characteristic_category = characteristic_group.find('span').text\n",
    "            # Initialize an empty list\n",
    "            characteristics_list = []\n",
    "            # Find all characteristics and iterate over them if they are more than 1, adding them to the list. Then add it to the car object, with the category as key.\n",
    "            characteristics = characteristic_group.find_all('div')\n",
    "            if len(characteristics) > 1:\n",
    "                for characteristic in characteristics:\n",
    "                    characteristics_list.append(characteristic.text)\n",
    "                car[characteristic_category] = characteristics_list\n",
    "            else:\n",
    "                car[characteristic_category] = characteristics[0].text\n",
    "        # Append the new car object to the car list\n",
    "        car_list.append(car)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the car list to a data frame, and save it to a csv file for safe keeping\n",
    "df = pd.DataFrame(car_list)\n",
    "df.to_csv(\"data.csv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a data frame starting from the csv file\n",
    "df = pd.read_csv(\"data.csv\", sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('description', axis=1, inplace=True)\n",
    "df['price'].replace(to_replace='\\.',value='', regex=True, inplace= True)\n",
    "df['price'].replace(to_replace='â‚¬ ',value='', regex=True, inplace=True)\n",
    "df['price'] = pd.to_numeric(df['price'])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9ee9fc14769d8cf589862327116898794ea643e8f14803590679e25e555b001f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
